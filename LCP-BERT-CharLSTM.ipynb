{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LCP_BERT+CharacterLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4c441debe7045a6af82ae4511d0411c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f2bbb42bc374289930aa84ef9368792",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd5150ac3ba9427c9e70c0102e4e1545",
              "IPY_MODEL_8e2c8ba2233548078f44d2ece78a47e3"
            ]
          }
        },
        "2f2bbb42bc374289930aa84ef9368792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd5150ac3ba9427c9e70c0102e4e1545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c45b5b508c2f4ceaa6e667e5acd290e6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9551386898a34a6bb016dd07c12748cc"
          }
        },
        "8e2c8ba2233548078f44d2ece78a47e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_353b50195b2d44748fcb32cd0e7eacd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.07MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1ff755125714ce3bf2b6f724674103b"
          }
        },
        "c45b5b508c2f4ceaa6e667e5acd290e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9551386898a34a6bb016dd07c12748cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "353b50195b2d44748fcb32cd0e7eacd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1ff755125714ce3bf2b6f724674103b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b62666decad342d28417e22ea2044a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdf4f3722a9d4121baef4c0627d824d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f46039b5018408982d34b3fd609d568",
              "IPY_MODEL_891943b3d02e41ddbefc244a7bd07d46"
            ]
          }
        },
        "cdf4f3722a9d4121baef4c0627d824d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f46039b5018408982d34b3fd609d568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f09f6451f5c64552b63f3f9cfd69ea71",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48825d3e2e00451fabf916ee64f0de04"
          }
        },
        "891943b3d02e41ddbefc244a7bd07d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_091ee9b20dfe4544ac42399c69b6d7c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.37kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c371995388a24dc98d17d5cff465359b"
          }
        },
        "f09f6451f5c64552b63f3f9cfd69ea71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48825d3e2e00451fabf916ee64f0de04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "091ee9b20dfe4544ac42399c69b6d7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c371995388a24dc98d17d5cff465359b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea4e96dbe4cf480e8cddf1c0545cc71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_015a5862046b4ed29caafc9a3381ddcb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_caa599fdd58f47dfb9e446881784dcc0",
              "IPY_MODEL_41f01cbc7901424180c343720462bf68"
            ]
          }
        },
        "015a5862046b4ed29caafc9a3381ddcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "caa599fdd58f47dfb9e446881784dcc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9efdf011746d47e5a5f2ed5a3ce20291",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fadff6e6bee4b298952fdeef042464f"
          }
        },
        "41f01cbc7901424180c343720462bf68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b36b5028ca546829d5053c5b226b75f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [01:40&lt;00:00, 4.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_605d73971d2d4f168b0f8b49d97b2103"
          }
        },
        "9efdf011746d47e5a5f2ed5a3ce20291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fadff6e6bee4b298952fdeef042464f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b36b5028ca546829d5053c5b226b75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "605d73971d2d4f168b0f8b49d97b2103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uFa0yISJ8Pk",
        "outputId": "b6ceefc9-9800-430e-a5a0-d7919d9ce36f"
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9MB 19.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 40.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzRUkrgjnFyR"
      },
      "source": [
        "# Gets the data\r\n",
        "\r\n",
        "%%bash\r\n",
        "rm -r sample_data\r\n",
        "wget -q 'https://www.dropbox.com/s/52fiyn199kgk0iq/datasets_combined.pkl?dl=1' -O 'datasets_combined.pkl'\r\n",
        "mkdir train\r\n",
        "cd train\r\n",
        "wget -q 'https://www.dropbox.com/s/cnw462g0oyo28i0/lcp_single_train.tsv?dl=1' -O 'lcp_single_train.tsv'\r\n",
        "wget -q 'https://www.dropbox.com/s/y1yoq24hzqbe5bf/lcp_multi_train.tsv?dl=1' -O 'lcp_multi_train.tsv'\r\n",
        "cd ..\r\n",
        "mkdir trial\r\n",
        "cd trial\r\n",
        "wget -q 'https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/trial/lcp_single_trial.tsv' -O 'lcp_single_trial.tsv'\r\n",
        "wget -q 'https://raw.githubusercontent.com/MMU-TDMLab/CompLex/master/trial/lcp_multi_trial.tsv' -O 'lcp_multi_trial.tsv'\r\n",
        "cd ..\r\n",
        "mkdir test\r\n",
        "cd test\r\n",
        "wget -q 'https://www.dropbox.com/s/mjcwx9wawealjk8/lcp_single_test.tsv?dl=1' -O 'lcp_single_test.tsv'\r\n",
        "wget -q 'https://www.dropbox.com/s/zil1h9xp7hrhkw1/lcp_multi_test.tsv?dl=1' -O 'lcp_multi_test.tsv'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wBbkDm5iVE6"
      },
      "source": [
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import spacy\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import os\r\n",
        "import csv\r\n",
        "import time\r\n",
        "from scipy.stats import pearsonr\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\r\n",
        "import torch\r\n",
        "import copy\r\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\r\n",
        "from transformers import BertModel, RobertaModel, BertTokenizer, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\r\n",
        "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\r\n",
        "import sklearn\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\r\n",
        "from sklearn.metrics import f1_score \r\n",
        "from tqdm import tqdm\r\n",
        "from transformers import AutoTokenizer, AutoModelForPreTraining\r\n",
        "RANDOM_SEED = 42\r\n",
        "np.random.seed(RANDOM_SEED)\r\n",
        "torch.manual_seed(RANDOM_SEED)\r\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PZg53Ino1L5"
      },
      "source": [
        "data = pd.read_csv('train/lcp_single_train.tsv',  delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEncOaduJH2W"
      },
      "source": [
        "for i, token in enumerate(list(data.token)):\r\n",
        "  if isinstance(token, float):\r\n",
        "    data.drop([i], inplace = True)\r\n",
        "    # print('Yes')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N-roJHCLlQ9"
      },
      "source": [
        "class Dataset():\r\n",
        "    def __init__(self, df, batch_size = 32, max_len = 128):\r\n",
        "        self.max_len = max_len\r\n",
        "        self.sentences = list(df.sentence)\r\n",
        "        self.tokens = list(df.token)\r\n",
        "        self.encoded_tokens, self.X_lengths = self.one_hot_batch(self.encode_tokens(list(df.token))[0])\r\n",
        "        \r\n",
        "        self.encoded_tokens = torch.FloatTensor(self.encoded_tokens)\r\n",
        "        self.X_lengths = torch.FloatTensor(self.X_lengths)\r\n",
        "        \r\n",
        "        self.complexity = torch.Tensor(list(df.complexity))\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.train_dataloader, self.val_dataloader = self.process_data()\r\n",
        "\r\n",
        "    def one_hot_word(self, encoded_tokens):\r\n",
        "        identity = torch.eye(26)\r\n",
        "        res = torch.Tensor(identity[encoded_tokens[0] - 1]).view(1, 26)\r\n",
        "        for each in (encoded_tokens)[1:]:\r\n",
        "          if each == 0:\r\n",
        "            res = torch.cat([res, torch.zeros(1, 26)])\r\n",
        "          else:\r\n",
        "            res = torch.cat([res, identity[each - 1].view(1, 26)])\r\n",
        "        return res\r\n",
        "\r\n",
        "    def one_hot_batch(self, encoded_tokens):\r\n",
        "        X_lengths = self.get_lengths(encoded_tokens)\r\n",
        "        final_res = self.one_hot_word(encoded_tokens[0]).view(1, 16, 26)\r\n",
        "        for i in range(encoded_tokens.shape[0] - 1):\r\n",
        "          one_hot_res = self.one_hot_word(encoded_tokens[i + 1])\r\n",
        "          final_res = torch.cat([final_res, one_hot_res.view(1, 16, 26)], dim = 0)\r\n",
        "        return final_res, X_lengths\r\n",
        "\r\n",
        "    def get_lengths(self, x):\r\n",
        "        X_lengths = []\r\n",
        "        for i in range(len(x)):\r\n",
        "            num = 0\r\n",
        "            while (num != 16 and x[i][num] != 0):\r\n",
        "                num += 1\r\n",
        "            X_lengths.append(num)\r\n",
        "        return X_lengths\r\n",
        "\r\n",
        "    def encode_tokens(self, tokens):\r\n",
        "        n_labels = 26\r\n",
        "        text = 'abcdefghijklmnopqrstuvwxyz'\r\n",
        "        chars = tuple(set(text))\r\n",
        "        intrange = set(i + 1 for i in range(26))\r\n",
        "        int2char = dict(zip(intrange, chars))\r\n",
        "        char2int = {ch: ii for ii, ch in int2char.items()}\r\n",
        "        encoded_list = []\r\n",
        "        for token in tokens:\r\n",
        "          token = token.lower()\r\n",
        "          encoded = np.array([char2int[ch] for ch in token])\r\n",
        "          encoded_list.append(torch.from_numpy(encoded))\r\n",
        "          padded_list, mask = self.padding_tensor(encoded_list)\r\n",
        "        return padded_list, mask\r\n",
        "\r\n",
        "    def padding_tensor(self, sequences):\r\n",
        "        num = len(sequences)\r\n",
        "        max_len = max([s.size(0) for s in sequences])\r\n",
        "        out_dims = (num, max_len)\r\n",
        "        out_tensor = sequences[0].data.new(*out_dims).fill_(0)\r\n",
        "        mask = sequences[0].data.new(*out_dims).fill_(0)\r\n",
        "        for i, tensor in enumerate(sequences):\r\n",
        "            length = tensor.size(0)\r\n",
        "            out_tensor[i, :length] = tensor\r\n",
        "            mask[i, :length] = 1\r\n",
        "        return out_tensor, mask\r\n",
        "    \r\n",
        "      \r\n",
        "    def process_data(self):\r\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "        input_ids, attention_masks = [], []\r\n",
        "        for sentence, token in zip(self.sentences, self.tokens):\r\n",
        "            sent = str(token).lower() + ' [SEP] ' +  str(sentence).lower() \r\n",
        "            encoded_dict = tokenizer.encode_plus(sent,\r\n",
        "                                                    add_special_tokens=True,\r\n",
        "                                                    max_length=self.max_len, \r\n",
        "                                                    padding='max_length', \r\n",
        "                                                    return_attention_mask = True,\r\n",
        "                                                    return_tensors = 'pt', \r\n",
        "                                                    truncation = True)\r\n",
        "            input_ids.append(encoded_dict['input_ids'])\r\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "        \r\n",
        "        input_ids = torch.cat(input_ids, dim=0)\r\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "\r\n",
        "        return self.get_dataloaders(input_ids, attention_masks)\r\n",
        "    \r\n",
        "    def get_dataloaders(self, input_ids, attention_masks):\r\n",
        "        input_ids, attention_masks, self.complexity, self.encoded_tokens, self.X_lengths = sklearn.utils.shuffle(input_ids, attention_masks, self.complexity, self.encoded_tokens, self.X_lengths, random_state=42)\r\n",
        "        train_idx, test_idx, _, _ = train_test_split(range(input_ids.shape[0]), input_ids, test_size = 0.2, random_state = 42)\r\n",
        "\r\n",
        "        training_data = TensorDataset(input_ids[train_idx], attention_masks[train_idx], self.complexity[train_idx], self.encoded_tokens[train_idx], self.X_lengths[train_idx])\r\n",
        "        training_sampler = RandomSampler(training_data)\r\n",
        "        training_dataloader = DataLoader(training_data, sampler=training_sampler, batch_size=self.batch_size)\r\n",
        "\r\n",
        "        test_data = TensorDataset(input_ids[test_idx], attention_masks[test_idx], self.complexity[test_idx], self.encoded_tokens[test_idx], self.X_lengths[test_idx])\r\n",
        "        test_sampler = SequentialSampler(test_data)\r\n",
        "        test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=self.batch_size)\r\n",
        "\r\n",
        "        return training_dataloader, test_dataloader"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puX_FSsZq9kt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "f4c441debe7045a6af82ae4511d0411c",
            "2f2bbb42bc374289930aa84ef9368792",
            "dd5150ac3ba9427c9e70c0102e4e1545",
            "8e2c8ba2233548078f44d2ece78a47e3",
            "c45b5b508c2f4ceaa6e667e5acd290e6",
            "9551386898a34a6bb016dd07c12748cc",
            "353b50195b2d44748fcb32cd0e7eacd7",
            "d1ff755125714ce3bf2b6f724674103b"
          ]
        },
        "outputId": "11f9f48f-f209-42a5-9732-e6955ab28169"
      },
      "source": [
        "start_time = time.time()\r\n",
        "dataset = Dataset(data, batch_size = 32)\r\n",
        "print(\"Time taken: \" + str((time.time() - start_time)/60))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4c441debe7045a6af82ae4511d0411c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken: 6.892130124568939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFc98ehrPliJ"
      },
      "source": [
        "class BERT_CharLSTM(torch.nn.Module):\r\n",
        "    def __init__(self, BERT_in, n_hidden=100, n_layers=2, seq_length=16, n_linear=500, drop_prob=0.25, lr=0.001):\r\n",
        "        \r\n",
        "        super(BERT_CharLSTM, self).__init__()\r\n",
        "\r\n",
        "        # CharLSTM\r\n",
        "        self.drop_prob = drop_prob\r\n",
        "        self.n_layers = n_layers\r\n",
        "        self.n_hidden = n_hidden\r\n",
        "        self.n_linear = n_linear\r\n",
        "        self.seq_length = seq_length\r\n",
        "        self.lr = lr\r\n",
        "\r\n",
        "        self.chars = 'abcdefghijklmnopqrstuvwxyz'\r\n",
        "        self.int2char = dict(enumerate(self.chars))\r\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\r\n",
        "        \r\n",
        "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \r\n",
        "                            dropout=drop_prob, batch_first=True, bidirectional = True)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(drop_prob)\r\n",
        "      \r\n",
        "        self.fc = nn.Linear(2*n_hidden*seq_length, n_linear, bias = True)\r\n",
        "\r\n",
        "        # BERT\r\n",
        "        self.embeddings = BertModel.from_pretrained('bert-base-uncased',  output_hidden_states = True)\r\n",
        "        self.final = nn.Linear(BERT_in, n_linear, bias = True)\r\n",
        "        self.dropout = nn.Dropout(drop_prob)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "        # Combined\r\n",
        "        self.final_1 = nn.Linear(2 * n_linear, 1, bias = True)\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "\r\n",
        "\r\n",
        "    def init_hidden(self, batch_size):\r\n",
        "\r\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \r\n",
        "        hidden = ((torch.zeros(2 * self.n_layers, batch_size, self.n_hidden)).to(device),\r\n",
        "                  (torch.zeros(2 * self.n_layers, batch_size, self.n_hidden)).to(device))\r\n",
        "\r\n",
        "        return hidden\r\n",
        "\r\n",
        "    def forward(self, x, x_mask, X_char, X_char_lengths, batch_size, hidden):\r\n",
        "\r\n",
        "        # CharLSTM\r\n",
        "        X = X_char\r\n",
        "        r_output, hidden = self.lstm(X, hidden)\r\n",
        "        out = r_output\r\n",
        "        out = self.dropout(out)\r\n",
        "        out = out.contiguous()\r\n",
        "        out = self.fc(out.view(out.shape[0], -1)) \r\n",
        "        out = self.relu(out)\r\n",
        "        out = out.view(out.shape[0], -1) \r\n",
        "\r\n",
        "        # BERT\r\n",
        "        embed = self.embeddings(x,x_mask)[1]\r\n",
        "        y_pred = self.relu(self.final(self.dropout(embed)))\r\n",
        "        y_pred = y_pred.view(y_pred.shape[0], -1) \r\n",
        "        \r\n",
        "        # Combined\r\n",
        "        final_inp = torch.cat([out, y_pred], dim = 1) \r\n",
        "        final_inp = self.final_1(final_inp)\r\n",
        "        final_inp = final_inp.view(final_inp.shape[0])\r\n",
        "        final_result = self.sigmoid(final_inp)\r\n",
        "\r\n",
        "        return final_result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCjQ3-AcQPyJ"
      },
      "source": [
        "def save_metrics(save_path, epochs, model, optimizer, L1):\r\n",
        "\r\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\r\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "                  'epochs': epochs+1,\r\n",
        "                  'L1': L1}\r\n",
        "    \r\n",
        "    torch.save(state_dict, save_path)\r\n",
        "    print(f'Model saved to ==> {save_path}')\r\n",
        "\r\n",
        "\r\n",
        "def load_metrics(load_path, model, optimizer):\r\n",
        "    try: \r\n",
        "        state_dict = torch.load(load_path, map_location=device)\r\n",
        "        model.load_state_dict(state_dict['model_state_dict'])\r\n",
        "        optimizer.load_state_dict(state_dict['optimizer_state_dict'])\r\n",
        "    except: \r\n",
        "        state_dict = {}\r\n",
        "\r\n",
        "    print(f'Model loaded from <== {load_path}')\r\n",
        "    \r\n",
        "    return state_dict.get('epochs', 0), state_dict.get('L1', 1000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn7tWK0FQQot"
      },
      "source": [
        "def evaluate(test_dataloader, model):\r\n",
        "    model.eval()\r\n",
        "    total_eval_accuracy=0\r\n",
        "    y_preds = np.array([])\r\n",
        "    y_test = np.array([])\r\n",
        "    total_loss = 0\r\n",
        "    criterion = nn.L1Loss()\r\n",
        "    hidden_charlstm = model.init_hidden(batch_size = 32)\r\n",
        "    for batch in test_dataloader:\r\n",
        "        hidden_charlstm = model.init_hidden(batch_size = batch[0].to(device).shape[0])\r\n",
        "        b_input_ids = batch[0].to(device)\r\n",
        "        b_input_mask = batch[1].to(device)\r\n",
        "        b_labels = batch[2].to(device)\r\n",
        "        b_X_char = batch[3].to(device)\r\n",
        "        b_X_char_lengths = batch[4].to(device)\r\n",
        "        with torch.no_grad():\r\n",
        "            ypred = model(b_input_ids, b_input_mask, b_X_char, b_X_char_lengths.cpu(), batch_size = 32, hidden = hidden_charlstm)        \r\n",
        "\r\n",
        "        ypred = ypred.to('cpu').numpy()\r\n",
        "        b_labels = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "        y_preds = np.hstack((y_preds, ypred))\r\n",
        "        y_test = np.hstack((y_test, b_labels))\r\n",
        "\r\n",
        "    loss = np.mean(np.abs(y_preds-y_test))\r\n",
        "    corr, _ = pearsonr(y_preds, y_test)\r\n",
        "    return loss, y_preds, y_test, corr\r\n",
        " \r\n",
        "def train(training_dataloader, validation_dataloader, model, filename, epochs = 4):\r\n",
        "    total_steps = len(training_dataloader) * epochs\r\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5, eps = 1e-8)\r\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                                num_warmup_steps = 0, # Default value in run_glue.py\r\n",
        "                                                num_training_steps = total_steps)\r\n",
        "    \r\n",
        "    criterion = nn.L1Loss()\r\n",
        "    best_model = copy.deepcopy(model)\r\n",
        "\r\n",
        "    hidden_charlstm = model.init_hidden(batch_size = 32)\r\n",
        "\r\n",
        "    cur_epoch, best_l1 = load_metrics(filename, model, optimizer)\r\n",
        "    for epoch_i in tqdm(range(0, epochs)):\r\n",
        "        total_train_loss = 0\r\n",
        "        model.train()\r\n",
        "        for step, batch in enumerate(training_dataloader):\r\n",
        "            hidden_charlstm = model.init_hidden(batch_size = batch[0].to(device).shape[0])\r\n",
        "            b_input_ids = batch[0].to(device)\r\n",
        "            b_input_mask = batch[1].to(device)\r\n",
        "            b_labels = batch[2].to(device)\r\n",
        "            b_X_char = batch[3].to(device)\r\n",
        "            b_X_char_lengths = batch[4].to(device)\r\n",
        "            outputs = model(b_input_ids, b_input_mask, b_X_char, b_X_char_lengths.cpu(), batch_size = 32, hidden = hidden_charlstm)\r\n",
        "            loss = criterion(outputs, b_labels)\r\n",
        " \r\n",
        "            if step%50 == 0:\r\n",
        "                print(loss)\r\n",
        " \r\n",
        "            total_train_loss += loss\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "            optimizer.step()\r\n",
        "            scheduler.step()\r\n",
        " \r\n",
        "        print()\r\n",
        "        print(f'Total Train Loss = {total_train_loss}')\r\n",
        "        print('#############    Validation Set Stats')\r\n",
        "        l1_loss, _, _, corr = evaluate(validation_dataloader, model)\r\n",
        "        print(\"  L1 loss: {}\".format(l1_loss))\r\n",
        "        print(\"  Pearson correlation: {}\".format(corr))\r\n",
        " \r\n",
        "        if l1_loss < best_l1:\r\n",
        "            best_l1 = l1_loss\r\n",
        "            save_metrics(filename, epoch_i, model, optimizer, l1_loss)\r\n",
        " "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3zctP8gQSz_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "b62666decad342d28417e22ea2044a0c",
            "cdf4f3722a9d4121baef4c0627d824d2",
            "2f46039b5018408982d34b3fd609d568",
            "891943b3d02e41ddbefc244a7bd07d46",
            "f09f6451f5c64552b63f3f9cfd69ea71",
            "48825d3e2e00451fabf916ee64f0de04",
            "091ee9b20dfe4544ac42399c69b6d7c8",
            "c371995388a24dc98d17d5cff465359b",
            "ea4e96dbe4cf480e8cddf1c0545cc71b",
            "015a5862046b4ed29caafc9a3381ddcb",
            "caa599fdd58f47dfb9e446881784dcc0",
            "41f01cbc7901424180c343720462bf68",
            "9efdf011746d47e5a5f2ed5a3ce20291",
            "6fadff6e6bee4b298952fdeef042464f",
            "3b36b5028ca546829d5053c5b226b75f",
            "605d73971d2d4f168b0f8b49d97b2103"
          ]
        },
        "outputId": "14d818f0-2b04-487e-99c3-ba8308364834"
      },
      "source": [
        "model = BERT_CharLSTM(768).to(device)\r\n",
        "# print(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b62666decad342d28417e22ea2044a0c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea4e96dbe4cf480e8cddf1c0545cc71b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkk6EAfHIbX_",
        "outputId": "442c06aa-62c0-4443-8d87-3db28df4017e"
      },
      "source": [
        "train(dataset.train_dataloader, dataset.val_dataloader, model, 'lcp_sigmoid.pt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== lcp_sigmoid.pt\n",
            "tensor(0.2300, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.1276, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.1099, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0675, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "\n",
            "Total Train Loss = 16.540884017944336\n",
            "#############    Validation Set Stats\n",
            "  L1 loss: 0.07069815868540975\n",
            "  Pearson correlation: 0.7702301196207733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 1/4 [02:29<07:28, 149.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved to ==> lcp_sigmoid.pt\n",
            "tensor(0.0725, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0652, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0584, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0603, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "\n",
            "Total Train Loss = 12.180423736572266\n",
            "#############    Validation Set Stats\n",
            "  L1 loss: 0.06400496618793038\n",
            "  Pearson correlation: 0.7847085065235135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 2/4 [05:03<05:01, 151.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved to ==> lcp_sigmoid.pt\n",
            "tensor(0.0708, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0513, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0614, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0328, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "\n",
            "Total Train Loss = 10.8983736038208\n",
            "#############    Validation Set Stats\n",
            "  L1 loss: 0.06337800334200419\n",
            "  Pearson correlation: 0.7959902627887484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 3/4 [07:38<02:32, 152.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved to ==> lcp_sigmoid.pt\n",
            "tensor(0.0621, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0545, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0630, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0611, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "\n",
            "Total Train Loss = 10.083100318908691\n",
            "#############    Validation Set Stats\n",
            "  L1 loss: 0.06288751905453306\n",
            "  Pearson correlation: 0.7965084786993971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [10:12<00:00, 153.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved to ==> lcp_sigmoid.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FkNXWIEiyid"
      },
      "source": [
        "# **TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZqMx-0VF34V"
      },
      "source": [
        "test_data = pd.read_csv('/content/test/lcp_single_test.tsv',  delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27EK0LoRaZBT"
      },
      "source": [
        "test_data.to_csv('test_original.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWwmgM0nRxFu"
      },
      "source": [
        "class TestDataset():\r\n",
        "    def __init__(self, df, batch_size = 32, max_len = 128):\r\n",
        "        self.max_len = max_len\r\n",
        "        self.sentences = list(df.sentence)\r\n",
        "        self.tokens = list(df.token)\r\n",
        "        self.encoded_tokens, self.X_lengths = self.one_hot_batch(self.encode_tokens(list(df.token))[0])\r\n",
        "        \r\n",
        "        self.encoded_tokens = torch.FloatTensor(self.encoded_tokens)\r\n",
        "        self.X_lengths = torch.FloatTensor(self.X_lengths)\r\n",
        "        \r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.test_dataloader = self.process_data()\r\n",
        "\r\n",
        "    def one_hot_word(self, encoded_tokens):\r\n",
        "        identity = torch.eye(26)\r\n",
        "        res = torch.Tensor(identity[encoded_tokens[0] - 1]).view(1, 26)\r\n",
        "        for each in (encoded_tokens)[1:]:\r\n",
        "          if each == 0:\r\n",
        "            res = torch.cat([res, torch.zeros(1, 26)])\r\n",
        "          else:\r\n",
        "            res = torch.cat([res, identity[each - 1].view(1, 26)])\r\n",
        "        return res\r\n",
        "\r\n",
        "    def one_hot_batch(self, encoded_tokens):\r\n",
        "        X_lengths = self.get_lengths(encoded_tokens)\r\n",
        "        final_res = self.one_hot_word(encoded_tokens[0]).view(1, 16, 26)\r\n",
        "        for i in range(encoded_tokens.shape[0] - 1):\r\n",
        "          one_hot_res = self.one_hot_word(encoded_tokens[i + 1])\r\n",
        "          final_res = torch.cat([final_res, one_hot_res.view(1, 16, 26)], dim = 0)\r\n",
        "        return final_res, X_lengths\r\n",
        "\r\n",
        "    def get_lengths(self, x):\r\n",
        "        X_lengths = []\r\n",
        "        for i in range(len(x)):\r\n",
        "            num = 0\r\n",
        "            while (num != 16 and x[i][num] != 0):\r\n",
        "                num += 1\r\n",
        "            X_lengths.append(num)\r\n",
        "        return X_lengths\r\n",
        "\r\n",
        "    def encode_tokens(self, tokens):\r\n",
        "        n_labels = 26\r\n",
        "        text = 'abcdefghijklmnopqrstuvwxyz'\r\n",
        "        chars = tuple(set(text))\r\n",
        "        intrange = set(i + 1 for i in range(26))\r\n",
        "        int2char = dict(zip(intrange, chars))\r\n",
        "        char2int = {ch: ii for ii, ch in int2char.items()}\r\n",
        "\r\n",
        "        encoded_list = []\r\n",
        "        for token in tokens:\r\n",
        "          token = token.lower()\r\n",
        "          encoded = np.array([char2int[ch] for ch in token])\r\n",
        "          encoded_list.append(torch.from_numpy(encoded))\r\n",
        "          padded_list, mask = self.padding_tensor(encoded_list)\r\n",
        "        return padded_list, mask\r\n",
        "\r\n",
        "    def padding_tensor(self, sequences):\r\n",
        "        num = len(sequences)\r\n",
        "        max_len = max([s.size(0) for s in sequences])\r\n",
        "        out_dims = (num, max_len)\r\n",
        "        out_tensor = sequences[0].data.new(*out_dims).fill_(0)\r\n",
        "        mask = sequences[0].data.new(*out_dims).fill_(0)\r\n",
        "        for i, tensor in enumerate(sequences):\r\n",
        "            length = tensor.size(0)\r\n",
        "            out_tensor[i, :length] = tensor\r\n",
        "            mask[i, :length] = 1\r\n",
        "        return out_tensor, mask\r\n",
        "    \r\n",
        "      \r\n",
        "    def process_data(self):\r\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "        input_ids, attention_masks = [], []\r\n",
        "        for sentence, token in zip(self.sentences, self.tokens):\r\n",
        "            sent = str(token).lower() + ' [SEP] ' +  str(sentence).lower() \r\n",
        "            encoded_dict = tokenizer.encode_plus(sent,\r\n",
        "                                                    add_special_tokens=True,\r\n",
        "                                                    max_length=self.max_len, \r\n",
        "                                                    padding='max_length', \r\n",
        "                                                    return_attention_mask = True,\r\n",
        "                                                    return_tensors = 'pt', \r\n",
        "                                                    truncation = True)\r\n",
        "            input_ids.append(encoded_dict['input_ids'])\r\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "        \r\n",
        "        input_ids = torch.cat(input_ids, dim=0)\r\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "\r\n",
        "        return self.get_dataloaders(input_ids, attention_masks)\r\n",
        "    \r\n",
        "    def get_dataloaders(self, input_ids, attention_masks):\r\n",
        "        test_data = TensorDataset(input_ids, attention_masks, self.encoded_tokens, self.X_lengths)\r\n",
        "        test_sampler = SequentialSampler(test_data)\r\n",
        "        test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=self.batch_size)\r\n",
        "        return test_dataloader"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs79RYy0-gLZ"
      },
      "source": [
        "for i, word in enumerate(list(test_data.token)):\r\n",
        "  ''.join(e for e in word if e.isalnum())\r\n",
        "  if len(word) > 16:\r\n",
        "    test_data.token[i] = word[:16]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxX9JydxUtR2"
      },
      "source": [
        "test_dataset = TestDataset(test_data, batch_size = 32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V00_xJkNScGy"
      },
      "source": [
        "def evaluate(test_dataloader, model):\r\n",
        "    model.eval()\r\n",
        "    y_preds = np.array([])\r\n",
        "    total_loss = 0\r\n",
        "    hidden_charlstm = model.init_hidden(batch_size = 32)\r\n",
        "    for batch in test_dataloader:\r\n",
        "        hidden_charlstm = model.init_hidden(batch_size = batch[0].to(device).shape[0])\r\n",
        "        b_input_ids = batch[0].to(device)\r\n",
        "        b_input_mask = batch[1].to(device)\r\n",
        "        b_X_char = batch[2].to(device)\r\n",
        "        b_X_char_lengths = batch[3].to(device)\r\n",
        "        with torch.no_grad():\r\n",
        "            ypred = model(b_input_ids, b_input_mask, b_X_char, b_X_char_lengths.cpu(), batch_size = 32, hidden = hidden_charlstm)        \r\n",
        "        ypred = ypred.to('cpu').numpy()\r\n",
        "\r\n",
        "    return y_preds"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skwTTsB4cvbv"
      },
      "source": [
        "model = BERT_CharLSTM(768).to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4DBdVjBdN_5",
        "outputId": "d27ca357-0f91-47bc-f382-e9a0eb041340"
      },
      "source": [
        "state_dict = torch.load(f = '/content/lcp_sigmoid.pt', map_location=device)\r\n",
        "model.load_state_dict(state_dict['model_state_dict'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjT19zUvcrcc"
      },
      "source": [
        "FINAL_PREDS = evaluate(test_dataset.test_dataloader, model)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzWwUPKteX1V"
      },
      "source": [
        "results_dataset = pd.DataFrame()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGGCiRE2e_7A"
      },
      "source": [
        "results_dataset['complexity'] = list(FINAL_PREDS)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqR-LYSgfGUd"
      },
      "source": [
        "results_dataset.to_csv('results_latest.csv')"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}